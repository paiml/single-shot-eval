# single-shot-eval - SLM Pareto Frontier Evaluation Framework
# Makefile with PMAT Integration for EXTREME TDD
# Generated by pmat, enhanced for Toyota Way quality standards

.PHONY: all check format lint test test-fast test-integration bench build build-release run clean install help coverage coverage-html mutants ci pmat-quality-gate pmat-rust-score pmat-validate-docs pmat-context evaluate evaluate-quick report

# =============================================================================
# Configuration
# =============================================================================

PROJECT_NAME := single-shot-eval
CARGO := cargo
RUSTFLAGS := -D warnings

# Coverage threshold (NASA standard: 85%, HIGH TDD: 94%)
COVERAGE_THRESHOLD := 94
MUTATION_THRESHOLD := 80

# =============================================================================
# Default Target
# =============================================================================

all: format check lint test build

# =============================================================================
# Core Development Targets
# =============================================================================

# Type check the code
check:
	$(CARGO) check --all-targets

# Format code with rustfmt
format:
	$(CARGO) fmt --all

# Check formatting (CI mode)
format-check:
	$(CARGO) fmt --all -- --check

# Lint with clippy (strict mode)
lint:
	RUSTFLAGS="$(RUSTFLAGS)" $(CARGO) clippy --all-targets -- -D warnings -D clippy::unwrap_used

# Run all tests
test:
	$(CARGO) test --all-features

# Run fast tests only (unit tests, <30s target)
# Pattern from bashrs/aprender: nextest + exclude slow tests
test-fast:
	@echo "‚ö° Running fast tests (target: <30s)..."
	@if command -v cargo-nextest >/dev/null 2>&1; then \
		time cargo nextest run --lib \
			--status-level skip \
			--failure-output immediate \
			-E 'not test(/test_run_with_baselines/)'; \
	else \
		echo "üí° Install cargo-nextest for faster tests: cargo install cargo-nextest"; \
		time $(CARGO) test --lib -- --skip test_run_with_baselines; \
	fi
	@echo "‚úÖ Fast tests passed"

# Run integration tests
test-integration:
	$(CARGO) test --test '*'

# Run benchmarks
bench:
	$(CARGO) bench

# Build debug binary
build:
	$(CARGO) build

# Build release binary
build-release:
	$(CARGO) build --release

# Run the application
run:
	$(CARGO) run --

# Clean build artifacts
clean:
	$(CARGO) clean
	rm -rf coverage/ *.profraw *.profdata deep_context.md

# Install the binary
install: build-release
	$(CARGO) install --path .

# =============================================================================
# EXTREME TDD Targets (Toyota Way: Two-Phase Coverage Pattern)
# =============================================================================

# Code Coverage - "make coverage" just works (bashrs pattern)
# Following: Two-Phase Pattern for reliable instrumentation
# NOTE: cargo-tarpaulin is BANNED (see deny.toml) - use cargo-llvm-cov only
coverage: ## Generate HTML coverage report and summary
	@echo "üìä Running comprehensive test coverage analysis..."
	@echo "üîç Checking for cargo-llvm-cov and cargo-nextest..."
	@which cargo-llvm-cov > /dev/null 2>&1 || (echo "üì¶ Installing cargo-llvm-cov..." && cargo install cargo-llvm-cov --locked)
	@which cargo-nextest > /dev/null 2>&1 || (echo "üì¶ Installing cargo-nextest..." && cargo install cargo-nextest --locked)
	@echo "üßπ Cleaning old coverage data..."
	@cargo llvm-cov clean --workspace
	@mkdir -p target/coverage
	@echo "‚öôÔ∏è  Temporarily disabling global cargo config (mold breaks coverage)..."
	@test -f ~/.cargo/config.toml && mv ~/.cargo/config.toml ~/.cargo/config.toml.cov-backup || true
	@echo "üß™ Phase 1: Running tests with instrumentation (no report)..."
	@echo "   (excluding slow baseline tests for <60s target)"
	@cargo llvm-cov --no-report nextest --no-tests=warn --all-features --workspace -E 'not test(/test_run_with_baselines/)'
	@echo "üìä Phase 2: Generating coverage reports..."
	@echo "   (excluding main.rs - CLI entry point not under test)"
	@cargo llvm-cov report --html --output-dir target/coverage/html --ignore-filename-regex 'main\.rs'
	@cargo llvm-cov report --lcov --output-path target/coverage/lcov.info --ignore-filename-regex 'main\.rs'
	@echo "‚öôÔ∏è  Restoring global cargo config..."
	@test -f ~/.cargo/config.toml.cov-backup && mv ~/.cargo/config.toml.cov-backup ~/.cargo/config.toml || true
	@echo ""
	@echo "üìä Coverage Summary:"
	@echo "=================="
	@cargo llvm-cov report --summary-only --ignore-filename-regex 'main\.rs'
	@echo ""
	@echo "üí° COVERAGE INSIGHTS:"
	@echo "- HTML report: target/coverage/html/index.html"
	@echo "- LCOV file: target/coverage/lcov.info"
	@echo "- Open HTML: make coverage-open"
	@echo ""

# Show coverage summary only (after running coverage)
coverage-summary: ## Show coverage summary
	@cargo llvm-cov report --summary-only --ignore-filename-regex 'main\.rs' 2>/dev/null || echo "Run 'make coverage' first"

# Open HTML coverage report in browser
coverage-open: ## Open HTML coverage report in browser
	@if [ -f target/coverage/html/index.html ]; then \
		xdg-open target/coverage/html/index.html 2>/dev/null || \
		open target/coverage/html/index.html 2>/dev/null || \
		echo "Please open: target/coverage/html/index.html"; \
	else \
		echo "‚ùå Run 'make coverage' first to generate the HTML report"; \
	fi

# Generate LCOV report for CI/CD (fast mode)
coverage-ci: ## Generate LCOV report for CI/CD
	@echo "=== Code Coverage for CI/CD ==="
	@echo "Phase 1: Running tests with instrumentation..."
	@cargo llvm-cov clean --workspace
	@cargo llvm-cov --no-report nextest --no-tests=warn --all-features --workspace
	@echo "Phase 2: Generating LCOV report..."
	@cargo llvm-cov report --lcov --output-path lcov.info --ignore-filename-regex 'main\.rs'
	@echo "‚úì Coverage report generated: lcov.info"

# Check coverage meets threshold (trueno pattern: Python enforcement with sys.exit)
coverage-check: ## Enforce 94% coverage threshold (BLOCKS on failure)
	@echo "üîí Enforcing $(COVERAGE_THRESHOLD)% coverage threshold..."
	@cargo llvm-cov report --ignore-filename-regex 'main\.rs' 2>/dev/null | python3 -c "import sys; lines = list(sys.stdin); total_line = [l for l in lines if l.startswith('TOTAL')]; exec('if not total_line: print(chr(9888) + chr(65039) + \" No coverage data. Run make coverage first.\"); sys.exit(1)') if not total_line else None; parts = total_line[0].split(); covered = int(parts[7]) - int(parts[8]); total = int(parts[7]); pct = 100 * covered / total if total > 0 else 0; print(f'Coverage: {pct:.2f}% ({covered:,}/{total:,} lines)'); threshold = $(COVERAGE_THRESHOLD); sys.exit(1) if pct < threshold and print(f'‚ùå FAIL: Coverage {pct:.2f}% below {threshold}% threshold') is None else print(f'‚úÖ Coverage threshold met (‚â•{threshold}%)')"

# Clean coverage artifacts
coverage-clean: ## Clean coverage artifacts
	@cargo llvm-cov clean --workspace 2>/dev/null || true
	@rm -f lcov.info coverage.xml target/coverage/lcov.info
	@rm -rf target/llvm-cov target/coverage target/llvm-cov-target
	@find . -name "*.profraw" -delete 2>/dev/null || true
	@echo "‚úì Coverage artifacts cleaned"

# Run mutation testing (requires cargo-mutants)
mutants: ## Run mutation testing analysis
	$(CARGO) mutants --timeout 60 || true
	@echo "Mutation testing complete. Check mutants.out/ for results."

# =============================================================================
# CI/CD Pipeline
# =============================================================================

# Full CI pipeline
ci: format-check check lint test coverage-check
	@echo "‚úÖ CI pipeline passed"

# Pre-commit validation (fast, <30s)
pre-commit: format-check lint test-fast
	@echo "‚úÖ Pre-commit checks passed"

# =============================================================================
# PMAT Integration (Dogfooding)
# =============================================================================

# Run PMAT quality gates
pmat-quality-gate:
	pmat quality-gate --strict

# Calculate Rust project score
pmat-rust-score:
	pmat rust-project-score --verbose

# Full Rust project score (includes clippy, mutation)
pmat-rust-score-full:
	pmat rust-project-score --full --verbose

# Generate deep context for documentation validation
pmat-context:
	pmat context --output deep_context.md --format llm-optimized

# Validate documentation accuracy
pmat-validate-docs: pmat-context
	pmat validate-readme --targets README.md CLAUDE.md --deep-context deep_context.md --fail-on-contradiction --verbose

# Run TDG analysis
pmat-tdg:
	pmat tdg --verbose

# Show quality metrics and trends
pmat-metrics:
	pmat show-metrics --trend

# =============================================================================
# Model Management (REPRODUCIBLE SCIENCE)
# =============================================================================
# Evaluating CODE SLMs for Python‚ÜíRust single-shot compilation
# Test corpus: ../reprorusted-python-cli (298 examples, 6,745 tests)
# Ground truth: Does generated Rust compile + pass tests?

# Paths
MODEL_CHECKSUMS := models/CHECKSUMS.sha256
CORPUS_PATH := ../reprorusted-python-cli/examples
BATUTA_STACK := ../batuta

# =============================================================================
# CODE-FOCUSED SLMs for Python‚ÜíRust Transpilation
# =============================================================================
# These models are specifically chosen for code generation tasks.
# All must be converted to .apr format for offline evaluation.

# Download code-focused SLMs from HuggingFace
models: models-download models-convert models-verify ## Download, convert, verify code SLMs
	@echo "‚úÖ All code SLMs ready for Python‚ÜíRust evaluation"

models-download: ## Download code-focused SLMs (GGUF format)
	@echo "üì• Downloading CODE SLMs for Python‚ÜíRust transpilation..."
	@mkdir -p models/raw
	@echo ""
	@echo "=== Qwen2.5-Coder (Best small code model) ==="
	@test -f models/raw/qwen2.5-coder-1.5b-instruct-q4_k_m.gguf || \
		(echo "  ‚Üí Qwen2.5-Coder-1.5B-Instruct Q4_K_M (~1GB)" && \
		curl -L -o models/raw/qwen2.5-coder-1.5b-instruct-q4_k_m.gguf \
		"https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-1.5b-instruct-q4_k_m.gguf")
	@echo ""
	@echo "=== DeepSeek-Coder (Strong code reasoning) ==="
	@test -f models/raw/deepseek-coder-1.3b-instruct-q4_k_m.gguf || \
		(echo "  ‚Üí DeepSeek-Coder-1.3B-Instruct Q4_K_M (~800MB)" && \
		curl -L -o models/raw/deepseek-coder-1.3b-instruct-q4_k_m.gguf \
		"https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q4_K_M.gguf")
	@echo ""
	@echo "=== StarCoder2 (Code-specialized) ==="
	@test -f models/raw/starcoder2-3b-q4_k_m.gguf || \
		(echo "  ‚Üí StarCoder2-3B Q4_K_M (~1.8GB)" && \
		curl -L -o models/raw/starcoder2-3b-q4_k_m.gguf \
		"https://huggingface.co/second-state/StarCoder2-3B-GGUF/resolve/main/starcoder2-3b-Q4_K_M.gguf")
	@echo ""
	@echo "=== Phi-2 (Microsoft, efficient) ==="
	@test -f models/raw/phi-2-q4_k_m.gguf || \
		(echo "  ‚Üí Phi-2 Q4_K_M (~1.6GB)" && \
		curl -L -o models/raw/phi-2-q4_k_m.gguf \
		"https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf")
	@echo ""
	@echo "‚úÖ Raw models downloaded to models/raw/"
	@ls -lh models/raw/*.gguf

models-convert: ## Convert GGUF models to .apr format (entrenar)
	@echo "üîÑ Converting GGUF ‚Üí .apr format using entrenar..."
	@which entrenar > /dev/null 2>&1 || (echo "‚ùå entrenar not found. Install from batuta stack" && exit 1)
	@for gguf in models/raw/*.gguf; do \
		apr="models/$$(basename $$gguf .gguf).apr"; \
		if [ ! -f "$$apr" ]; then \
			echo "  Converting: $$gguf ‚Üí $$apr"; \
			entrenar convert --input "$$gguf" --output "$$apr" || echo "  ‚ö†Ô∏è  Failed: $$gguf"; \
		else \
			echo "  ‚úì Already exists: $$apr"; \
		fi; \
	done
	@echo "‚úÖ Conversion complete"
	@ls -lh models/*.apr 2>/dev/null || echo "No .apr models"

models-verify: ## Verify model checksums
	@echo "üîê Verifying model checksums..."
	@if [ -f $(MODEL_CHECKSUMS) ]; then \
		cd models && sha256sum -c CHECKSUMS.sha256 && echo "‚úÖ Checksums verified"; \
	else \
		echo "‚ö†Ô∏è  No checksums. Generating..."; \
		$(MAKE) models-checksum; \
	fi

models-checksum: ## Generate SHA256 checksums
	@cd models && sha256sum *.apr > CHECKSUMS.sha256 2>/dev/null || echo "No .apr models"
	@cat $(MODEL_CHECKSUMS) 2>/dev/null || true

models-list: ## List available models
	@echo "=== .apr Models (ready for evaluation) ==="
	@ls -lh models/*.apr 2>/dev/null || echo "  (none - run 'make models')"
	@echo ""
	@echo "=== Raw GGUF downloads ==="
	@ls -lh models/raw/*.gguf 2>/dev/null || echo "  (none)"

models-clean: ## Remove all models
	@rm -rf models/raw models/*.apr models/CHECKSUMS.sha256
	@echo "‚úÖ Models cleaned"

# =============================================================================
# Test Corpus (reprorusted-python-cli)
# =============================================================================

corpus-check: ## Verify test corpus exists
	@echo "üîç Checking test corpus: $(CORPUS_PATH)"
	@test -d $(CORPUS_PATH) || (echo "‚ùå Corpus not found: $(CORPUS_PATH)" && exit 1)
	@echo "  Examples: $$(ls -d $(CORPUS_PATH)/*/ 2>/dev/null | wc -l)"
	@echo "  Python files: $$(find $(CORPUS_PATH) -name '*.py' | wc -l)"
	@echo "‚úÖ Corpus ready"

corpus-sample: ## Show sample from corpus
	@echo "=== Sample Python CLI from corpus ==="
	@ls $(CORPUS_PATH) | head -5
	@echo ""
	@echo "=== Example structure ==="
	@ls $(CORPUS_PATH)/$$(ls $(CORPUS_PATH) | head -1)/ 2>/dev/null | head -10

# =============================================================================
# Evaluation: Python‚ÜíRust Single-Shot Compilation
# =============================================================================
# Ground truth: cargo build && cargo test passes

evaluate: corpus-check ## Run full Pareto evaluation
	@echo "üî¨ Evaluating Python‚ÜíRust single-shot compilation"
	@echo "   Corpus: $(CORPUS_PATH)"
	@echo "   Models: $$(ls models/*.apr 2>/dev/null | wc -l) SLMs"
	@echo "   Baselines: claude, gemini (SaaS ground truth)"
	@test -n "$$(ls models/*.apr 2>/dev/null)" || (echo "‚ùå No models. Run 'make models'" && exit 1)
	$(CARGO) run --release -- evaluate \
		--corpus $(CORPUS_PATH) \
		--models models/*.apr \
		--baselines claude,gemini \
		--output results/$$(date +%Y%m%d_%H%M%S)

evaluate-quick: corpus-check ## Quick evaluation (10 examples)
	@echo "üî¨ Quick evaluation (10 examples)..."
	$(CARGO) run --release -- evaluate \
		--corpus $(CORPUS_PATH) \
		--models models/*.apr \
		--samples 10 \
		--output results/quick-$$(date +%Y%m%d_%H%M%S)

evaluate-offline: corpus-check ## Offline-only evaluation (no SaaS)
	@echo "üî¨ OFFLINE evaluation (batuta stack only, no internet)..."
	@test -n "$$(ls models/*.apr 2>/dev/null)" || (echo "‚ùå No models. Run 'make models'" && exit 1)
	$(CARGO) run --release -- evaluate \
		--corpus $(CORPUS_PATH) \
		--models models/*.apr \
		--offline \
		--output results/offline-$$(date +%Y%m%d_%H%M%S)

report: ## Generate Pareto frontier report
	$(CARGO) run --release -- report \
		--input results/latest \
		--output reports/pareto-frontier.md

# Full reproducible workflow
reproduce: models corpus-check evaluate report ## Full reproducible evaluation
	@echo "‚úÖ Reproducible evaluation complete"
	@echo "   Models: models/*.apr"
	@echo "   Corpus: $(CORPUS_PATH)"
	@echo "   Results: results/"
	@echo "   Report: reports/pareto-frontier.md"

# =============================================================================
# Setup Targets
# =============================================================================

# Install development dependencies
setup:
	rustup component add rustfmt clippy llvm-tools-preview
	cargo install cargo-llvm-cov cargo-mutants cargo-nextest
	@echo "‚úÖ Development dependencies installed"

# Initialize PMAT integration
pmat-init:
	pmat work init --no-github
	pmat hooks install --tdg-enforcement --force
	@echo "‚úÖ PMAT integration initialized"

# =============================================================================
# Help
# =============================================================================

help:
	@echo "$(PROJECT_NAME) - SLM Pareto Frontier Evaluation Framework"
	@echo ""
	@echo "üöÄ QUICK START (Reproducible Science):"
	@echo "  make models     - Download & convert reference SLM models"
	@echo "  make evaluate   - Run full evaluation suite"
	@echo "  make reproduce  - Full reproducible workflow (models + eval + report)"
	@echo ""
	@echo "Core Targets:"
	@echo "  all             - Run format, check, lint, test, and build"
	@echo "  check           - Type check the code"
	@echo "  format          - Format code with rustfmt"
	@echo "  lint            - Run clippy linter (strict mode)"
	@echo "  test            - Run all tests"
	@echo "  test-fast       - Run unit tests only (<30s, excludes slow baseline tests)"
	@echo "  build           - Build debug binary"
	@echo "  build-release   - Build optimized release binary"
	@echo "  run             - Run the application"
	@echo "  clean           - Remove build artifacts"
	@echo ""
	@echo "Model Management (REPRODUCIBLE SCIENCE):"
	@echo "  models          - Download, convert, and verify all reference models"
	@echo "  models-download - Download reference models from HuggingFace"
	@echo "  models-convert  - Convert downloaded models to .apr format"
	@echo "  models-verify   - Verify model checksums for reproducibility"
	@echo "  models-checksum - Generate checksums for current models"
	@echo "  models-list     - List available .apr models"
	@echo "  models-validate - Validate all models are .apr format"
	@echo "  models-clean    - Remove all downloaded models"
	@echo ""
	@echo "Evaluation Targets:"
	@echo "  evaluate        - Run full evaluation suite (requires models)"
	@echo "  evaluate-quick  - Quick smoke test (100 samples)"
	@echo "  evaluate-smol   - Evaluate SmolLM-135M only (fastest)"
	@echo "  report          - Generate Pareto frontier report"
	@echo "  reproduce       - Full reproducible evaluation workflow"
	@echo ""
	@echo "EXTREME TDD Targets:"
	@echo "  coverage        - Generate HTML coverage report (two-phase pattern)"
	@echo "  coverage-summary - Show coverage summary"
	@echo "  coverage-open   - Open HTML coverage in browser"
	@echo "  coverage-ci     - Generate LCOV for CI/CD"
	@echo "  coverage-check  - Verify coverage >= $(COVERAGE_THRESHOLD)%"
	@echo "  coverage-clean  - Clean coverage artifacts"
	@echo "  mutants         - Run mutation testing"
	@echo ""
	@echo "CI/CD Targets:"
	@echo "  ci              - Full CI pipeline"
	@echo "  pre-commit      - Fast pre-commit validation"
	@echo ""
	@echo "PMAT Integration:"
	@echo "  pmat-quality-gate    - Run PMAT quality gates"
	@echo "  pmat-rust-score      - Calculate Rust project score"
	@echo "  pmat-validate-docs   - Validate documentation accuracy"
	@echo "  pmat-tdg             - Run TDG analysis"
	@echo "  pmat-metrics         - Show quality metrics and trends"
	@echo "  pmat-init            - Initialize PMAT integration"
	@echo ""
	@echo "Setup:"
	@echo "  setup           - Install development dependencies"
